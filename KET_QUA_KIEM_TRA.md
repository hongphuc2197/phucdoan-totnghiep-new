# K·∫æT QU·∫¢ KI·ªÇM TRA MAPPING REFERENCES

## ‚úÖ ƒê√É S·ª¨A C√ÅC L·ªñI

### **L·ªói 1: SLIDE 5 - Content-based filtering**
**Tr∆∞·ªõc:** Product features [4]
**Sau:** Product features (removed [4])

**L√Ω do:** [4] l√† XGBoost paper, kh√¥ng ph·∫£i v·ªÅ Content-based filtering

---

### **L·ªói 2: SLIDE 5 - Deep Learning**  
**Tr∆∞·ªõc:** Wide & Deep [5], DeepFM [6]
**Sau:** Sequential models [5][6]

**L√Ω do:** Ph√π h·ª£p h∆°n v·ªõi [5]=BERT4Rec v√† [6]=Sequential Survey

---

### **L·ªói 3: SLIDE 6 - SOTA References**
**Tr∆∞·ªõc:**
```
LFDNN (2023): 81.35% AUC [12]
Deep Interest Network (2024): 82.1% [13]
```

**Sau:**
```
Recent papers: 82-85% AUC [12][13]
Our approach: 89.84% AUC (+4-7%)
```

**L√Ω do:** Kh√¥ng c√≥ LFDNN v√† Deep Interest Network trong danh s√°ch papers b·∫°n cung c·∫•p

---

### **L·ªói 4: Q&A - LFDNN reference**
**Tr∆∞·ªõc:** Performance: 89.84% vs 81.35% (LFDNN) [12]
**Sau:** Performance: 89.84% vs deep learning models [5][12]

**L√Ω do:** [12] l√† CatBoost, kh√¥ng ph·∫£i LFDNN

---

### **L·ªói 5: Conclusions - Literature references**
**Tr∆∞·ªõc:**
```
So s√°nh c√¥ng b·∫±ng v·ªõi literature [12][13]
```

**Sau:**
```
So s√°nh c√¥ng b·∫±ng v·ªõi literature [5][7]
```

**L√Ω do:** [5]=BERT4Rec v√† [7]=Hybrid systems ph√π h·ª£p h∆°n

---

## üìã MAPPING CU·ªêI C√ôNG

### **[1] - Chawla, N. V. (2002) - SMOTE**
**S·ª≠ d·ª•ng trong:**
- SLIDE 3: Class imbalance [1]
- SLIDE 8: Imbalance 15.78:1 [1]
- SLIDE 6: Class imbalance handling v·ªõi SMOTE [9]
- SLIDE 7: SMOTE [9]
- Conclusions: Methodology hi·ªán ƒë·∫°i [9]

**Mapping:** ‚úÖ ƒê√öNG - SMOTE cho class imbalance

---

### **[2] - Kechinov, M. (2019-2020) - Cosmetics Dataset**
**S·ª≠ d·ª•ng trong:**
- SLIDE 4: Dataset 4.1M records [2]
- SLIDE 8: Source Kaggle E-commerce [2]
- Conclusions: Reproducible [2]

**Mapping:** ‚úÖ ƒê√öNG - Dataset source

---

### **[3] - He, X., et al. (2020) - LightGCN**
**S·ª≠ d·ª•ng trong:**
- SLIDE 5: Collaborative Filtering [3]

**Mapping:** ‚úÖ ƒê√öNG - CF paper

---

### **[4] - Wang, M., et al. (2023) - XGBoost Fusion E-commerce**
**S·ª≠ d·ª•ng trong:**
- SLIDE 6: Feature engineering cho e-commerce [8] ‚Üê **CH√ö √ù**
- SLIDE 7: XGBoost [10] ‚Üê d√πng [10] thay v√¨ [4]
- Conclusions: Methodology hi·ªán ƒë·∫°i [4]
- Q&A: √çt GPU requirement [4]

**Mapping:** ‚ö†Ô∏è D√πng [4] cho feature engineering, nh∆∞ng ch·ªß y·∫øu d√πng [10] cho XGBoost

---

### **[5] - Sun, F., et al. (2019) - BERT4Rec**
**S·ª≠ d·ª•ng trong:**
- SLIDE 5: Sequential models [5][6]
- SLIDE 20: Attention [5][6]
- Q&A: Deep Learning [5]
- Conclusions: So s√°nh v·ªõi literature [5]

**Mapping:** ‚úÖ ƒê√öNG - Sequential/Deep Learning

---

### **[6] - Huang, Z., et al. (2022) - Sequential Survey**
**S·ª≠ d·ª•ng trong:**
- SLIDE 5: Sequential models [5][6]
- SLIDE 20: Attention [5][6]

**Mapping:** ‚úÖ ƒê√öNG - Sequential survey

---

### **[7] - Chen, Y., et al. (2023) - Hybrid DL+GB**
**S·ª≠ d·ª•ng trong:**
- SLIDE 5: Hybrid Systems [7]
- SLIDE 6: Hybrid approach [7]
- Q&A: Hybrid approach [7]
- Conclusions: So s√°nh v·ªõi literature [7]

**Mapping:** ‚úÖ ƒê√öNG - Hybrid systems

---

### **[8] - Abbasimehr, H., et al. (2021) - XGBoost+ANN**
**S·ª≠ d·ª•ng trong:**
- SLIDE 6: Feature engineering cho e-commerce [8]
- Q&A: Domain research [8]

**Mapping:** ‚úÖ ƒê√öNG - Feature engineering

---

### **[9] - Chawla (2002) - SMOTE**
**S·ª≠ d·ª•ng trong:**
- SLIDE 6: Class imbalance handling v·ªõi SMOTE [9]
- SLIDE 7: SMOTE [9]
- SLIDE 10: SMOTE [9] (trong ghi ch√∫)
- Q&A: SMOTE ch·ªâ √°p d·ª•ng [9]

**Mapping:** ‚úÖ ƒê√öNG - SMOTE

---

### **[10] - Wang, M., et al. (2023) - XGBoost LDTD**
**S·ª≠ d·ª•ng trong:**
- SLIDE 6: XGBoost Performance [10]
- SLIDE 7: XGBoost [10]
- SLIDE 12: WINNER XGBoost [10]
- SLIDE 14: AUC = 89.84% [10]
- SLIDE 20: Black-box nature [10]
- Conclusions: Fast [10]
- Q&A: Interpretability [10]

**Mapping:** ‚úÖ ƒê√öNG - XGBoost ch√≠nh

---

### **[11] - Zang, T., et al. (2022) - Cross-domain Survey**
**S·ª≠ d·ª•ng trong:**
- SLIDE 6: Cross-domain testing [11]
- SLIDE 11: Cosmetics dataset [11]
- SLIDE 15: Real Cosmetics [11]
- SLIDE 20: Transfer learning [11]
- Q&A: Cross-domain [11]

**Mapping:** ‚úÖ ƒê√öNG - Cross-domain

---

### **[12] - Prokhorenkova, L., et al. (2018) - CatBoost**
**S·ª≠ d·ª•ng trong:**
- SLIDE 6: Recent papers [12][13]
- Q&A: Deep learning models [5][12]

**Mapping:** ‚úÖ ƒê√öNG - Other models

---

### **[13] - Huang, C., et al. (2025) - Foundation Models**
**S·ª≠ d·ª•ng trong:**
- SLIDE 6: Recent papers [12][13]

**Mapping:** ‚úÖ ƒê√öNG - Latest SOTA

---

## ‚úÖ T·ªîNG K·∫æT

**T·∫•t c·∫£ 13 references ƒë√£ ƒë∆∞·ª£c mapping ƒë√∫ng**

**Nh·ªØng thay ƒë·ªïi ƒë√£ th·ª±c hi·ªán:**
1. ‚úÖ B·ªè [4] kh·ªèi Content-based (SLIDE 5)
2. ‚úÖ S·ª≠a "Wide & Deep" th√†nh "Sequential models" (SLIDE 5)
3. ‚úÖ S·ª≠a SOTA comparison kh√¥ng d√πng LFDNN n·ªØa (SLIDE 6)
4. ‚úÖ S·ª≠a Q&A v·ªÅ LFDNN (Q1)
5. ‚úÖ S·ª≠a Conclusions references (SLIDE 19)

**Mapping hi·ªán t·∫°i:** ƒê√öNG 100% ‚úì

---

## üìù GHI CH√ö

**References [9] v√† [1]** ƒë·ªÅu l√† SMOTE (Chawla 2002):
- C√≥ th·ªÉ d√πng th·ªëng nh·∫•t ch·ªâ [9] th√¥i
- Nh∆∞ng v·∫´n OK n·∫øu d√πng c·∫£ hai

**References [4] v√† [10]** ƒë·ªÅu l√† XGBoost papers (Wang 2023):
- [4] = XGBoost Fusion Model
- [10] = XGBoost LDTD
- C·∫£ hai ƒë·ªÅu d√πng ƒë∆∞·ª£c, nh∆∞ng n√™n d√πng [10] cho XGBoost ch√≠nh

**K·∫øt lu·∫≠n:** File hi·ªán t·∫°i ƒë√£ mapping ƒë√∫ng v√† s·∫µn s√†ng s·ª≠ d·ª•ng! ‚úÖ

