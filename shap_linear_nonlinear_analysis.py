import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import shap
import joblib
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

# Set style for better visualization
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

print("="*80)
print("ğŸ” SHAP PHÃ‚N TÃCH TUYáº¾N TÃNH vs PHI TUYáº¾N - MÃ” HÃŒNH XGBOOST")
print("="*80)

# Load the trained model and scaler
print("ğŸ“¥ Äang táº£i mÃ´ hÃ¬nh XGBoost Ä‘Ã£ huáº¥n luyá»‡n...")
try:
    model = joblib.load('best_model_xgboost.pkl')
    scaler = joblib.load('scaler.pkl')
    print("âœ… ÄÃ£ táº£i thÃ nh cÃ´ng mÃ´ hÃ¬nh vÃ  scaler")
except FileNotFoundError:
    print("âŒ KhÃ´ng tÃ¬m tháº¥y file mÃ´ hÃ¬nh. Vui lÃ²ng cháº¡y fast_model_comparison.py trÆ°á»›c.")
    exit()

# Load processed data
print("ğŸ“¥ Äang táº£i dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½...")
try:
    df = pd.read_csv('processed_data.csv')
    print(f"âœ… ÄÃ£ táº£i {len(df):,} báº£n ghi")
except FileNotFoundError:
    print("âŒ KhÃ´ng tÃ¬m tháº¥y file processed_data.csv. Vui lÃ²ng cháº¡y analyze_dataset.py trÆ°á»›c.")
    exit()

# Sample data for SHAP analysis (faster computation)
print("ğŸ”„ Láº¥y máº«u dá»¯ liá»‡u cho phÃ¢n tÃ­ch SHAP...")
df_sample = df.sample(n=min(10000, len(df)), random_state=42)

# Prepare features - use only the features that were used during training
# These are the features that the scaler was trained on
feature_columns = [
    'price', 'total_purchases', 'total_events', 'purchase_rate', 'avg_price', 'price_std', 
    'min_price', 'max_price', 'unique_products', 'unique_categories', 
    'session_duration_days', 'product_purchases', 'product_views', 'product_purchase_rate', 
    'product_price', 'unique_users', 'category_purchases', 'category_views', 
    'category_purchase_rate', 'category_price', 'category_users', 'price_ratio', 
    'is_expensive', 'price_category_encoded'
]

# Filter to only include features that exist in the dataset
feature_columns = [col for col in feature_columns if col in df_sample.columns]

X_sample = df_sample[feature_columns]
y_sample = df_sample['purchased']

# Scale features
X_sample_scaled = scaler.transform(X_sample)

print(f"ğŸ“Š PhÃ¢n tÃ­ch trÃªn {len(X_sample):,} máº«u vá»›i {len(feature_columns)} features")

# Create SHAP explainer
print("ğŸ”§ Äang táº¡o SHAP explainer...")
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_sample_scaled)

print("âœ… ÄÃ£ tÃ­nh toÃ¡n SHAP values thÃ nh cÃ´ng")

# Define linear and non-linear features based on domain knowledge
linear_features = [
    'total_purchases', 'purchase_rate', 'product_purchases', 
    'category_purchases', 'total_views', 'cart_additions'
]

nonlinear_features = [
    'price_ratio', 'session_duration_days', 'avg_session_duration',
    'unique_categories', 'category_views', 'is_expensive'
]

# Ensure all features exist in the dataset
linear_features = [f for f in linear_features if f in feature_columns]
nonlinear_features = [f for f in nonlinear_features if f in feature_columns]

print(f"ğŸ“ˆ Features tuyáº¿n tÃ­nh: {len(linear_features)}")
print(f"ğŸ“Š Features phi tuyáº¿n: {len(nonlinear_features)}")

# Create comprehensive visualization
fig = plt.figure(figsize=(24, 16))
gs = fig.add_gridspec(3, 4, hspace=0.4, wspace=0.3)

# 1. SHAP Summary Plot - All Features
ax1 = fig.add_subplot(gs[0, :2])
shap.summary_plot(shap_values, X_sample_scaled, feature_names=feature_columns, 
                  max_display=15, show=False)
ax1.set_title('SHAP Summary Plot - Táº¥t cáº£ Features', fontsize=16, fontweight='bold', pad=20)

# 2. SHAP Summary Plot - Linear Features Only
ax2 = fig.add_subplot(gs[0, 2:])
linear_indices = [feature_columns.index(f) for f in linear_features if f in feature_columns]
if linear_indices:
    shap.summary_plot(shap_values[:, linear_indices], X_sample_scaled[:, linear_indices], 
                      feature_names=linear_features, max_display=len(linear_features), 
                      show=False)
    ax2.set_title('SHAP Summary - Features Tuyáº¿n TÃ­nh', fontsize=16, fontweight='bold', pad=20)

# 3. SHAP Summary Plot - Non-linear Features Only
ax3 = fig.add_subplot(gs[1, :2])
nonlinear_indices = [feature_columns.index(f) for f in nonlinear_features if f in feature_columns]
if nonlinear_indices:
    shap.summary_plot(shap_values[:, nonlinear_indices], X_sample_scaled[:, nonlinear_indices], 
                      feature_names=nonlinear_features, max_display=len(nonlinear_features), 
                      show=False)
    ax3.set_title('SHAP Summary - Features Phi Tuyáº¿n', fontsize=16, fontweight='bold', pad=20)

# 4. Feature Importance Comparison
ax4 = fig.add_subplot(gs[1, 2:])
feature_importance = np.abs(shap_values).mean(0)
feature_importance_df = pd.DataFrame({
    'feature': feature_columns,
    'importance': feature_importance
}).sort_values('importance', ascending=True)

# Color by linear/non-linear
colors = []
for feature in feature_importance_df['feature']:
    if feature in linear_features:
        colors.append('lightblue')
    elif feature in nonlinear_features:
        colors.append('lightcoral')
    else:
        colors.append('lightgray')

bars = ax4.barh(range(len(feature_importance_df)), feature_importance_df['importance'], 
                color=colors, alpha=0.8, edgecolor='black', linewidth=0.5)
ax4.set_yticks(range(len(feature_importance_df)))
ax4.set_yticklabels(feature_importance_df['feature'], fontsize=10)
ax4.set_xlabel('Mean |SHAP Value|', fontsize=12, fontweight='bold')
ax4.set_title('Feature Importance - PhÃ¢n loáº¡i Tuyáº¿n/Phi tuyáº¿n', fontsize=16, fontweight='bold', pad=20)

# Add legend
from matplotlib.patches import Patch
legend_elements = [Patch(facecolor='lightblue', label='Tuyáº¿n tÃ­nh'),
                  Patch(facecolor='lightcoral', label='Phi tuyáº¿n'),
                  Patch(facecolor='lightgray', label='KhÃ¡c')]
ax4.legend(handles=legend_elements, loc='lower right')

# 5. Linear vs Non-linear Impact Analysis
ax5 = fig.add_subplot(gs[2, :2])
linear_impact = np.abs(shap_values[:, linear_indices]).mean() if linear_indices else 0
nonlinear_impact = np.abs(shap_values[:, nonlinear_indices]).mean() if nonlinear_indices else 0

categories = ['Tuyáº¿n tÃ­nh', 'Phi tuyáº¿n']
impacts = [linear_impact, nonlinear_impact]
colors = ['lightblue', 'lightcoral']

bars = ax5.bar(categories, impacts, color=colors, alpha=0.8, edgecolor='black', linewidth=2)
ax5.set_ylabel('Mean |SHAP Value|', fontsize=12, fontweight='bold')
ax5.set_title('TÃ¡c Ä‘á»™ng Tá»•ng thá»ƒ: Tuyáº¿n tÃ­nh vs Phi tuyáº¿n', fontsize=16, fontweight='bold', pad=20)

# Add value labels on bars
for bar, impact in zip(bars, impacts):
    height = bar.get_height()
    ax5.text(bar.get_x() + bar.get_width()/2., height + 0.001,
             f'{impact:.4f}', ha='center', va='bottom', fontweight='bold', fontsize=12)

# 6. Detailed Feature Analysis
ax6 = fig.add_subplot(gs[2, 2:])
# Create a detailed comparison table
comparison_data = []
for feature in feature_columns:
    if feature in feature_importance_df['feature'].values:
        importance = feature_importance_df[feature_importance_df['feature'] == feature]['importance'].iloc[0]
        feature_type = 'Tuyáº¿n tÃ­nh' if feature in linear_features else 'Phi tuyáº¿n' if feature in nonlinear_features else 'KhÃ¡c'
        comparison_data.append([feature, importance, feature_type])

comparison_df = pd.DataFrame(comparison_data, columns=['Feature', 'Importance', 'Type'])
comparison_df = comparison_df.sort_values('Importance', ascending=True)

# Create horizontal bar plot
y_pos = np.arange(len(comparison_df))
colors = ['lightblue' if t == 'Tuyáº¿n tÃ­nh' else 'lightcoral' if t == 'Phi tuyáº¿n' else 'lightgray' 
          for t in comparison_df['Type']]

bars = ax6.barh(y_pos, comparison_df['Importance'], color=colors, alpha=0.8, edgecolor='black', linewidth=0.5)
ax6.set_yticks(y_pos)
ax6.set_yticklabels(comparison_df['Feature'], fontsize=9)
ax6.set_xlabel('Mean |SHAP Value|', fontsize=12, fontweight='bold')
ax6.set_title('Chi tiáº¿t Feature Importance', fontsize=16, fontweight='bold', pad=20)

plt.tight_layout()
plt.savefig('shap_linear_nonlinear_analysis.png', dpi=300, bbox_inches='tight')
print("âœ… ÄÃ£ lÆ°u biá»ƒu Ä‘á»“ SHAP phÃ¢n tÃ­ch: shap_linear_nonlinear_analysis.png")

# Generate detailed analysis report
print("\n" + "="*80)
print("ğŸ“Š PHÃ‚N TÃCH CHI TIáº¾T TUYáº¾N TÃNH vs PHI TUYáº¾N")
print("="*80)

print(f"\nğŸ” Tá»”NG QUAN:")
print(f"   â€¢ Tá»•ng sá»‘ features: {len(feature_columns)}")
print(f"   â€¢ Features tuyáº¿n tÃ­nh: {len(linear_features)}")
print(f"   â€¢ Features phi tuyáº¿n: {len(nonlinear_features)}")
print(f"   â€¢ Máº«u phÃ¢n tÃ­ch: {len(X_sample):,} records")

if linear_indices:
    linear_avg_impact = np.abs(shap_values[:, linear_indices]).mean()
    print(f"\nğŸ“ˆ FEATURES TUYáº¾N TÃNH:")
    print(f"   â€¢ TÃ¡c Ä‘á»™ng trung bÃ¬nh: {linear_avg_impact:.4f}")
    print(f"   â€¢ CÃ¡c features chÃ­nh:")
    linear_importance = np.abs(shap_values[:, linear_indices]).mean(0)
    linear_df = pd.DataFrame({
        'feature': linear_features,
        'importance': linear_importance
    }).sort_values('importance', ascending=False)
    
    for i, (_, row) in enumerate(linear_df.head(5).iterrows(), 1):
        print(f"      {i}. {row['feature']}: {row['importance']:.4f}")

if nonlinear_indices:
    nonlinear_avg_impact = np.abs(shap_values[:, nonlinear_indices]).mean()
    print(f"\nğŸ“Š FEATURES PHI TUYáº¾N:")
    print(f"   â€¢ TÃ¡c Ä‘á»™ng trung bÃ¬nh: {nonlinear_avg_impact:.4f}")
    print(f"   â€¢ CÃ¡c features chÃ­nh:")
    nonlinear_importance = np.abs(shap_values[:, nonlinear_indices]).mean(0)
    nonlinear_df = pd.DataFrame({
        'feature': nonlinear_features,
        'importance': nonlinear_importance
    }).sort_values('importance', ascending=False)
    
    for i, (_, row) in enumerate(nonlinear_df.head(5).iterrows(), 1):
        print(f"      {i}. {row['feature']}: {row['importance']:.4f}")

print(f"\nğŸ’¡ Káº¾T LUáº¬N:")
if linear_indices and nonlinear_indices:
    if linear_avg_impact > nonlinear_avg_impact:
        print(f"   â€¢ Features tuyáº¿n tÃ­nh cÃ³ tÃ¡c Ä‘á»™ng lá»›n hÆ¡n ({linear_avg_impact:.4f} vs {nonlinear_avg_impact:.4f})")
        print(f"   â€¢ MÃ´ hÃ¬nh XGBoost táº­n dá»¥ng tá»‘t má»‘i quan há»‡ tuyáº¿n tÃ­nh")
    else:
        print(f"   â€¢ Features phi tuyáº¿n cÃ³ tÃ¡c Ä‘á»™ng lá»›n hÆ¡n ({nonlinear_avg_impact:.4f} vs {linear_avg_impact:.4f})")
        print(f"   â€¢ MÃ´ hÃ¬nh XGBoost táº­n dá»¥ng tá»‘t má»‘i quan há»‡ phi tuyáº¿n")
    
    print(f"   â€¢ XGBoost cÃ¢n báº±ng tá»‘t giá»¯a cáº£ hai loáº¡i má»‘i quan há»‡")
    print(f"   â€¢ Äiá»u nÃ y giáº£i thÃ­ch táº¡i sao XGBoost vÆ°á»£t trá»™i hÆ¡n cÃ¡c mÃ´ hÃ¬nh tuyáº¿n tÃ­nh")

print(f"\nğŸ¯ Ã NGHÄ¨A THá»°C TIá»„N:")
print(f"   â€¢ MÃ´ hÃ¬nh cÃ³ thá»ƒ há»c Ä‘Æ°á»£c cáº£ patterns Ä‘Æ¡n giáº£n (tuyáº¿n tÃ­nh) vÃ  phá»©c táº¡p (phi tuyáº¿n)")
print(f"   â€¢ PhÃ¹ há»£p vá»›i báº£n cháº¥t Ä‘a dáº¡ng cá»§a hÃ nh vi ngÆ°á»i dÃ¹ng e-commerce")
print(f"   â€¢ Giáº£i thÃ­ch Ä‘Æ°á»£c cáº£ má»‘i quan há»‡ trá»±c tiáº¿p vÃ  giÃ¡n tiáº¿p trong dá»¯ liá»‡u")

print(f"\nğŸ“ FILES ÄÃƒ Táº O:")
print(f"   â€¢ shap_linear_nonlinear_analysis.png - Biá»ƒu Ä‘á»“ phÃ¢n tÃ­ch SHAP")
print(f"   â€¢ BÃ¡o cÃ¡o chi tiáº¿t trong console")

print("\nğŸŠ PHÃ‚N TÃCH SHAP HOÃ€N THÃ€NH!")
print("="*80)