,AUC_Score,Dataset,Task,Features,Method,Year,Training,Complexity,Innovation,Relevance,Source,Key_Features
Molar (2024),N/A (NDCG@10: 0.823),Sequential Recommendation Datasets,Sequential Recommendation,Multimodal (Text + Non-text),Multimodal LLM + Collaborative Filtering,2024,Fine-tuned LLM,Very High,Multimodal LLM with collaborative filtering alignment,High - Directly related to recommendation systems,Hugging Face Papers (arxiv:2412.18176),"Text + Non-text data integration, ID information, collaborative signals"
STAR (2024),N/A (Hits@10: +23.8% on Beauty),Amazon Review Dataset,Next Item Prediction,Semantic embeddings + Collaborative info,Training-free LLM + Retrieval + Ranking,2024,No Training Required,Low,Simple training-free approach using LLMs,Very High - Directly applicable to our task,Hugging Face Papers (arxiv:2410.16458),Semantic similarity + collaborative relationship + temporal decay
360Brew (2025),N/A (Production-level performance),LinkedIn Data (150B parameters),Personalized Ranking and Recommendation,Textual interface + Natural language,Decoder-only Foundation Model (150B),2025,Large-scale Fine-tuning,Extremely High,Single model for 30+ predictive tasks,High - Foundation model approach,Hugging Face Papers (arxiv:2501.16450),"Textual interface, eliminates feature engineering, generalizes to new domains"
